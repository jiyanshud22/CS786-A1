{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiyanshud22/CS786-A1/blob/main/CS786A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vafX0rWet791"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "from copy import deepcopy,copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0qlnCe_LvZ9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3080d24-16eb-46f8-bb49-403182ed87a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: brian2 in /usr/local/lib/python3.10/dist-packages (2.5.4)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.26.4)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from brian2) (3.0.11)\n",
            "Requirement already satisfied: sympy>=1.2 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.13.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from brian2) (3.1.4)\n",
            "Requirement already satisfied: jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from brian2) (3.1.4)\n",
            "Requirement already satisfied: setuptools>=61 in /usr/local/lib/python3.10/dist-packages (from brian2) (69.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brian2) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.7->brian2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.2->brian2) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install brian2\n",
        "from brian2 import *\n",
        "import random\n",
        "import math\n",
        "from neurodynex3.hopfield_network import network, pattern_tools, plot_tools\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_xuxEjCvjLU"
      },
      "source": [
        "## Integrate-and-fire neuron model  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUfAhdZkvp7B"
      },
      "source": [
        "This is one of the simplest models of neuron behavior. It omits all the intricacies of what goes on electrochemically inside the neuron's body, and simply attempts to capture the basic 'accumulate till a threshold and then fire and let go of all the accumulation' aspect of a neuron's activity\n",
        "\n",
        "$$\\frac{dv}{dt} = \\frac{(v_0 - v)}{\\tau},$$\n",
        "\n",
        "where $v$ is the membrane voltage of the neuron, and $\\tau$ is a timescale factor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "vUM8psGHvaAJ"
      },
      "outputs": [],
      "source": [
        "v0 = 1\n",
        "tau = 10*ms\n",
        "eqs = '''\n",
        "dv/dt = (v0-v)/tau : 1\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8m9qRJHFvaC8"
      },
      "outputs": [],
      "source": [
        "\n",
        "G = NeuronGroup(1, eqs, threshold='v>0.8', reset='v = 0', method='exact')\n",
        "M = StateMonitor(G, 'v', record=True)\n",
        "spikemon = SpikeMonitor(G)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jcg4589RvaGJ"
      },
      "outputs": [],
      "source": [
        "run(100*ms)\n",
        "plot(M.t/ms, M.v[0])\n",
        "xlabel('Time (ms)')\n",
        "ylabel('v')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX4Fzm29wfQz"
      },
      "source": [
        "## Hopfield network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAWMBM0nwh7U"
      },
      "source": [
        "In this simplified Hopfied model, each neuron can only take values +1 or -1. The network stores pixel patterns, and attempts to retrieve them given some cue in the form of a part of the original pattern used to set an initial state $S_i(t=0)$ for every neuron in the network. The network activation of all the neurons evolves as follows\n",
        "\n",
        "$$S_i(t+1) = sgn\\left(\\sum_j{w_{ij} S_j(t)}\\right), $$\n",
        "\n",
        "where the weight of every synaptic connection is calculated as,\n",
        "\n",
        "$$w_{ij} = \\frac{1}{N} \\sum_{\\mu}{p_i^\\mu p_j^\\mu}, $$\n",
        "\n",
        "where in turn, $N$ is the number of neurons, and $p_i^\\mu$ is the state of the $i^{th}$ neuron for encoding pattern $\\mu$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2ZHzXqewlEG"
      },
      "source": [
        "The code below is taken from this [link](https://neuronaldynamics-exercises.readthedocs.io/en/latest/exercises/hopfield-network.html). Follow the accompanying exercises to be better prepared for your assignment. Remember to install all needed libraries before trying to run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqTgsyd1vaIg"
      },
      "outputs": [],
      "source": [
        "!pip install neurodynex3\n",
        "%matplotlib inline\n",
        "from neurodynex3.hopfield_network import network, pattern_tools, plot_tools\n",
        "\n",
        "pattern_size = 4\n",
        "\n",
        "# create an instance of the class HopfieldNetwork\n",
        "hopfield_net = network.HopfieldNetwork(nr_neurons= pattern_size**2)\n",
        "# instantiate a pattern factory\n",
        "factory = pattern_tools.PatternFactory(pattern_size, pattern_size)\n",
        "# create a checkerboard pattern and add it to the pattern list\n",
        "checkerboard = factory.create_checkerboard()\n",
        "pattern_list = [checkerboard]\n",
        "\n",
        "# add random patterns to the list\n",
        "pattern_list.extend(factory.create_random_pattern_list(nr_patterns=4, on_probability=0.5))\n",
        "plot_tools.plot_pattern_list(pattern_list)\n",
        "# how similar are the random patterns and the checkerboard? Check the overlaps\n",
        "overlap_matrix = pattern_tools.compute_overlap_matrix(pattern_list)\n",
        "#plot_tools.plot_overlap_matrix(overlap_matrix)\n",
        "\n",
        "# let the hopfield network \"learn\" the patterns. Note: they are not stored\n",
        "# explicitly but only network weights are updated !\n",
        "hopfield_net.store_patterns(pattern_list)\n",
        "\n",
        "# create a noisy version of a pattern and use that to initialize the network\n",
        "noisy_init_state = pattern_tools.flip_n(checkerboard, nr_of_flips=4)\n",
        "hopfield_net.set_state_from_pattern(noisy_init_state)\n",
        "\n",
        "# from this initial state, let the network dynamics evolve.\n",
        "states = hopfield_net.run_with_monitoring(nr_steps=3)\n",
        "\n",
        "# each network state is a vector. reshape it to the same shape used to create the patterns.\n",
        "states_as_patterns = factory.reshape_patterns(states)\n",
        "# plot the states of the network\n",
        "plot_tools.plot_state_sequence_and_overlap(states_as_patterns, pattern_list, reference_idx=0, suptitle=\"Network dynamics\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfJ3--rRwzoc"
      },
      "source": [
        "## Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF4oUbDIw1tJ"
      },
      "source": [
        "Q1. Can you write you own Hopfield network model that works more or less like the one simulated above? (20 points)\n",
        "\n",
        "Q2. Run the model with different parameters to figure out how the model's capacity to retrieve the correct pattern in response to a cue deteriorates as a function of\n",
        "(a) the informativeness of the cue\n",
        "(b) the number of other patterns stored in the network\n",
        "(c) the size of the network\n",
        "\n",
        "Present your answers with plots and/or math. (20 points)\n",
        "\n",
        "Q3. Can you write a function that converts MNIST digit [data](https://gitlab.com/datapythonista/mnist) to the sort of patterns used in this simulation? (20 points)\n",
        "\n",
        "Q4. Can you write an MNIST classifier using the Hopfield network?. Can you characterize its performance using F-score, and compare with [classical](https://github.com/ksopyla/svm_mnist_digit_classification) and [deep](https://github.com/hwalsuklee/tensorflow-mnist-cnn) supervised learning methods? Remember that you can always use multiple samples of the same digit even for the Hopfield network classifier. Summarize your sense of the merits and demerits of using a Hopfield network as a classifier (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GbPnvegwrLq"
      },
      "source": [
        "## Q1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92CIdrk4O5lZ"
      },
      "source": [
        "## Our own Hopfield network model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm creating my own Hopfield Network model using the provided skeleton code. After looking at the skeleton, I realized that a few functions need to be completed.\n",
        "\n"
      ],
      "metadata": {
        "id": "cTsXc9QUfd2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_patterns(pattern_size, number_of_patterns):\n",
        " This function will create a list of patterns. Each pattern will be a square array filled with random values of either -1 or 1. The size of each square will be pattern_size x pattern_size, and the total number of patterns will be number_of_patterns."
      ],
      "metadata": {
        "id": "If1pn4cqgKGk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYljfPpNvaNs"
      },
      "outputs": [],
      "source": [
        "# Q1, Part 1: Function to generate pattern matrices with random -1 and 1 values\n",
        "import numpy as np\n",
        "import random as rand\n",
        "\n",
        "def create_pattern_matrix(size):\n",
        "    # Creates a matrix with random -1 and 1 values.\n",
        "    matrix = []\n",
        "    for row in range(size):\n",
        "        current_row = []\n",
        "        for col in range(size):\n",
        "            # Adds a random -1 or 1 to the current row\n",
        "            current_row.append(rand.choice([-1, 1]))\n",
        "        matrix.append(current_row)\n",
        "    return matrix\n",
        "\n",
        "def get_patterns(size, total_patterns):\n",
        "    # Generates a list of random pattern matrices.\n",
        "    pattern_list = []\n",
        "    for _ in range(total_patterns):\n",
        "        # Adds a newly generated pattern matrix to the list\n",
        "        pattern_list.append(create_pattern_matrix(size))\n",
        "    return np.array(pattern_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The flip_pattern_bits function\n",
        "It will generate pattern list whose values will contain -1 or 1 randomly. It will contain square arrays of size pattern_size*pattern_size and count will be number_of_patterns."
      ],
      "metadata": {
        "id": "SZ5UV1ZKhs6Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46zJL2uSvaQd"
      },
      "outputs": [],
      "source": [
        "# Q1, Part 2: Function to flip bits in the pattern\n",
        "def flip_pattern_bits(pattern, flip_count):\n",
        "    # Randomly flips bits in the given pattern.\n",
        "    num_columns = len(pattern[0])\n",
        "    num_rows = len(pattern)\n",
        "    flipped_positions = set()\n",
        "    flips_done = 0\n",
        "\n",
        "    while flips_done != flip_count:\n",
        "        # Randomly select a row and column to flip.\n",
        "        selected_row = rand.choice(range(num_rows))\n",
        "        selected_col = rand.choice(range(num_columns))\n",
        "\n",
        "        # If this bit was already flipped, skip to the next iteration.\n",
        "        if f\"{selected_row}-{selected_col}\" in flipped_positions:\n",
        "            continue\n",
        "        else:\n",
        "            # Flip the bit in the pattern.\n",
        "            pattern[selected_row][selected_col] = 1 if pattern[selected_row][selected_col] == -1 else -1\n",
        "            flips_done += 1\n",
        "            flipped_positions.add(f\"{selected_row}-{selected_col}\")\n",
        "\n",
        "    return pattern\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating weight matrix:\n",
        "\n",
        "According to formula in class slides\n",
        "\n",
        " ![Screenshot 2024-09-01 143540.png](data:image/png;base64,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)We can see that for getting wij.\n",
        " we take summation over all pattern.\n",
        "\n",
        "So we will design function that will calculate the above matrix in iterative manner.\n",
        "\n",
        "### adjust_weights:\n",
        "Updates the weights between neurons using a single pattern, ensuring symmetry and skipping diagonal elements."
      ],
      "metadata": {
        "id": "cg95NmVXiGhR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lx0DYqUvaSy"
      },
      "outputs": [],
      "source": [
        "# Q1, Part 3: Functions to compute the weight matrix\n",
        "import math\n",
        "\n",
        "def adjust_weights(single_pattern, weights_matrix, pattern_dimension, total_weights):\n",
        "    # Helper function to adjust weights using a single pattern.\n",
        "    for index_i in range(total_weights):\n",
        "        for index_j in range(total_weights):\n",
        "            if index_i == index_j:\n",
        "                continue  # Skip diagonal elements (set to 0).\n",
        "\n",
        "            if index_i > index_j:\n",
        "                # Use symmetry to copy the value to the symmetric position.\n",
        "                weights_matrix[index_i][index_j] = weights_matrix[index_j][index_i]\n",
        "            else:\n",
        "                row_i = int(math.floor(index_i / pattern_dimension))\n",
        "                col_i = int(index_i % pattern_dimension)\n",
        "                row_j = int(math.floor(index_j / pattern_dimension))\n",
        "                col_j = int(index_j % pattern_dimension)\n",
        "                weights_matrix[index_i][index_j] += single_pattern[row_i][col_i] * single_pattern[row_j][col_j]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compute_weights_naive:\n",
        "Iteratively calculates the weight matrix using all patterns, then normalizes the weights.\n",
        "\n",
        "Since using for loops is slower, I have also made another function calculate_weights_vectorized to speed up the process the functions\n",
        "\n",
        "### compute_weights_vectorized:\n",
        "Uses matrix multiplication to quickly calculate the weight matrix, then sets diagonal elements to zero and normalizes the result."
      ],
      "metadata": {
        "id": "by-jOsvH2LhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_weights_naive(pattern_collection, pattern_dimension):\n",
        "    # Basic implementation to compute the weight matrix.\n",
        "    total_weights = pattern_dimension**2\n",
        "    weights_matrix = [[0 for _ in range(total_weights)] for _ in range(total_weights)]\n",
        "\n",
        "    for pattern in pattern_collection:\n",
        "        # Update weights using each pattern.\n",
        "        adjust_weights(pattern, weights_matrix, pattern_dimension, total_weights)\n",
        "\n",
        "    # Normalize the weights by dividing by the total number of weights.\n",
        "    for index_i in range(total_weights):\n",
        "        for index_j in range(total_weights):\n",
        "            weights_matrix[index_i][index_j] /= total_weights\n",
        "\n",
        "    return weights_matrix\n",
        "\n",
        "def compute_weights_vectorized(pattern_collection, pattern_dimension):\n",
        "    # Optimized vectorized implementation to compute the weight matrix.\n",
        "    pattern_collection = np.array(pattern_collection)\n",
        "    total_weights = pattern_dimension**2\n",
        "    weights_matrix = np.zeros((total_weights, total_weights))\n",
        "\n",
        "    # Reshape the pattern collection into a 2D array where each row is a flattened pattern.\n",
        "    flattened_patterns = pattern_collection.reshape(len(pattern_collection), -1)\n",
        "\n",
        "    # Perform matrix multiplication to compute the weight matrix.\n",
        "    weights_matrix = np.matmul(flattened_patterns.T, flattened_patterns)\n",
        "\n",
        "    # Set diagonal elements to 0.\n",
        "    np.fill_diagonal(weights_matrix, 0)\n",
        "    return weights_matrix / total_weights\n"
      ],
      "metadata": {
        "id": "bjlfSWaK172l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used formula from book in the below function, formula is:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "- **Si(t + 1)**: The state of neuron **i** at the next time step.\n",
        "- **Σ**: The summation symbol, summing over all **j**.\n",
        "- **w_ij**: The weight between neuron **i** and neuron **j**.\n",
        "- **Sj(t)**: The state of neuron **j** at the current time step.\n",
        "- **sgn**: The sign function, which returns 1 if the input is positive, and -1 if the input is negative."
      ],
      "metadata": {
        "id": "xvlWK_usjzgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function updates the network’s state based on the above formula.\n",
        "\n",
        "- It uses an initial state and weights to compute the next state.\n",
        "- There are two methods: a basic (naive) method and a faster, vectorized method.\n",
        "- The main code uses the faster, optimized approach to update the state efficiently."
      ],
      "metadata": {
        "id": "XspNmRA2kI_F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5WD4vL4vaVa"
      },
      "outputs": [],
      "source": [
        "# Q1, Part 4: Functions to update the network state\n",
        "def network_update_basic(initial_state, weight_matrix):\n",
        "    num_neurons = len(weight_matrix)\n",
        "    pattern_size = len(initial_state)\n",
        "    new_state = [[0 for _ in range(pattern_size)] for _ in range(pattern_size)]\n",
        "\n",
        "    for i in range(num_neurons):\n",
        "        row_i = int(math.floor(i / pattern_size))\n",
        "        col_i = int(i % pattern_size)\n",
        "        for j in range(num_neurons):\n",
        "            row_j = int(math.floor(j / pattern_size))\n",
        "            col_j = int(j % pattern_size)\n",
        "            new_state[row_i][col_i] += weight_matrix[i][j] * initial_state[row_j][col_j]\n",
        "\n",
        "    for i in range(pattern_size):\n",
        "        for j in range(pattern_size):\n",
        "            new_state[i][j] = 1 if new_state[i][j] > 0 else -1\n",
        "\n",
        "    return np.array(new_state)\n",
        "\n",
        "def network_update_optimized(initial_state, weight_matrix):\n",
        "    pattern_size = len(initial_state)\n",
        "    new_state = np.multiply(weight_matrix, initial_state.flatten())\n",
        "    new_state = np.sum(new_state, axis=1)\n",
        "    new_state = new_state.reshape(pattern_size, pattern_size)\n",
        "    new_state[new_state <= 0] = -1\n",
        "    new_state[new_state > 0] = 1\n",
        "    return np.array(new_state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I Using the above functions to define function for hopfield network."
      ],
      "metadata": {
        "id": "PrgGfw6Jkwag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s9uosGMvaYB"
      },
      "outputs": [],
      "source": [
        "# Q1, Part 5: Main function to run the Hopfield Network\n",
        "from copy import deepcopy\n",
        "\n",
        "def hopfield_network(number_of_perturbs=3, number_of_patterns=5, pattern_size=4, plot_output=True):\n",
        "    # Generate a list of patterns\n",
        "    pattern_list = get_patterns(pattern_size, number_of_patterns)\n",
        "\n",
        "    # Copy the pattern list to create a cue\n",
        "    cue = deepcopy(pattern_list)\n",
        "\n",
        "    # Perturb the first pattern in the cue list\n",
        "    perturbed_pattern = flip_pattern_bits(cue[0], number_of_perturbs)\n",
        "\n",
        "    # Calculate the weight matrix from the pattern list\n",
        "    weights = compute_weights_vectorized(pattern_list, pattern_size)\n",
        "\n",
        "    # Initialize state list with the perturbed pattern\n",
        "    state_list = [perturbed_pattern]\n",
        "\n",
        "    for _ in range(4):\n",
        "        # Update the network state and store the new state\n",
        "        new_state = network_update_optimized(state_list[-1], weights)\n",
        "        state_list.append(new_state)\n",
        "\n",
        "    # Plot the results if required\n",
        "    if plot_output:\n",
        "        plot_tools.plot_pattern_list(pattern_list)  # Plot the initial pattern list\n",
        "        plot_tools.plot_pattern(state_list[0])      # Plot the perturbed pattern\n",
        "        plot_tools.plot_state_sequence_and_overlap(state_list, pattern_list, reference_idx=0, suptitle=\"Network Dynamics\")\n",
        "\n",
        "    # Calculate and return the overlap of the final state with the original pattern\n",
        "    overlap_value = pattern_tools.compute_overlap(state_list[-1], pattern_list[0])\n",
        "\n",
        "    return overlap_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will run the above function using following parameters\n",
        "\n",
        "number of perturbs = 3\n",
        "\n",
        "number of patterns = 5\n",
        "\n",
        "pattern size = 4"
      ],
      "metadata": {
        "id": "iNfXPT1SlCem"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMzJaNYXvaat"
      },
      "outputs": [],
      "source": [
        "overlap_value = hopfield_network(number_of_perturbs=3, number_of_patterns=6, pattern_size=5, plot_output=True)\n",
        "# weights, S, state_list = hopfield_network(number_of_perturbs=3, number_of_patterns=5, pattern_size=4, plot_output=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2"
      ],
      "metadata": {
        "id": "RQ6FwmpApXFi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INFORMATIVENESS OF CUE\n",
        "\n",
        "Informativeness of cue, meaning perturbing the pattern. We will see how is the model capacity detoriates by visualizing through graphs\n",
        "\n",
        "Plotting over perturb range of 1 to 100 for different pattern sizes\n",
        "\n",
        "Note that the \"m\" value we get is cosine similarity"
      ],
      "metadata": {
        "id": "Z3XHJu3ZpY9n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1I8ieSPvadD"
      },
      "outputs": [],
      "source": [
        "# Q2, Part 1: Testing the effect of the informativeness of the cue on model performance\n",
        "perturbs = range(1, 63)\n",
        "pattern_size1 = 8\n",
        "pattern_size2 = 9\n",
        "pattern_size3 = 10\n",
        "number_of_patterns = 10\n",
        "\n",
        "output1 = []\n",
        "output2 = []\n",
        "output3 = []\n",
        "\n",
        "for perturn_no in perturbs:\n",
        "    output1.append(hopfield_network(perturn_no, number_of_patterns, pattern_size1))\n",
        "    output2.append(hopfield_network(perturn_no, number_of_patterns, pattern_size2))\n",
        "    output3.append(hopfield_network(perturn_no, number_of_patterns, pattern_size3))\n",
        "\n",
        "plt.plot(output1)\n",
        "plt.plot(output2)\n",
        "plt.plot(output3)\n",
        "plt.legend([\"8\", \"9\", \"10\"], title=\"Pattern Size\")\n",
        "plt.xlabel(\"Number of Flips\")\n",
        "plt.ylabel(\"Similarity measure (m value)\")\n",
        "plt.title(\"Similarity measure vs number of flips\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus we can see that there is a downwards trend in the similarity measure on increasing number of flips. This means that if informativeness of cue deteriorate too much, Models capacity to retrieve the pattern worsens. This means Hopfield Network will behave poorly on decreasing informativeness of the cue and will get better if cues informativeness is not decreased.\n",
        "\n",
        "## NUMBER OF PATTERNS\n",
        "\n",
        "Checking models capacity upon number of patterns"
      ],
      "metadata": {
        "id": "x5YvIcZcsByU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueHDX3tTvafZ"
      },
      "outputs": [],
      "source": [
        "# Q2, Part 2: Testing the effect of the number of patterns on model performance\n",
        "pattern_number_list = range(3, 100)\n",
        "pattern_size1 = 8\n",
        "pattern_size2 = 9\n",
        "pattern_size3 = 10\n",
        "number_of_perturbs = 15\n",
        "\n",
        "output1 = []\n",
        "output2 = []\n",
        "output3 = []\n",
        "for number_of_patterns in pattern_number_list:\n",
        "    output1.append(hopfield_network(number_of_perturbs, number_of_patterns, pattern_size1))\n",
        "    output2.append(hopfield_network(number_of_perturbs, number_of_patterns, pattern_size2))\n",
        "    output3.append(hopfield_network(number_of_perturbs, number_of_patterns, pattern_size3))\n",
        "\n",
        "plt.plot(output1)\n",
        "plt.plot(output2)\n",
        "plt.plot(output3)\n",
        "\n",
        "plt.legend([\"8\", \"9\", \"10\"], title=\"Pattern Size\")\n",
        "plt.xlabel(\"Number of patterns\")\n",
        "plt.ylabel(\"Similarity measure (m value)\")\n",
        "plt.title(\"Similarity measure vs Number of patterns\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, theres not so obvious but a downwards trend when we increase number of patterns, where Networks quality to retain information is deteriorating on increasing number of patterns. A possible reason for this could be related to the amount of information hopfield pattern can store is finite and limited. So if we feed it more number of patters, quality will deteriorate. Probablity of error REF\n",
        "\n",
        "## PATTERN SIZE\n",
        "\n",
        "We will now run the code over various pattern sizes and see the performance of network. We will keep number of perturbs fixed to 15 and number of patters 20"
      ],
      "metadata": {
        "id": "xOTH0EgNsJPI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HybUl2DqvaiB"
      },
      "outputs": [],
      "source": [
        "# Q2, Part 3: Testing the effect of pattern size on model performance\n",
        "number_of_patterns = 20\n",
        "pattern_size_list = range(4, 20)\n",
        "number_of_perturbs = 15\n",
        "output = []\n",
        "\n",
        "for pattern_size in pattern_size_list:\n",
        "    output.append(hopfield_network(number_of_perturbs, number_of_patterns, pattern_size))\n",
        "\n",
        "plt.title(\"Pattern Size vs Similarity Measure\")\n",
        "plt.xlabel(\"Pattern Size\")\n",
        "plt.ylabel(\"Similarity measure (m value)\")\n",
        "plt.plot(output)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that performance of model increasing by increasing the pattern size. This is because higher the pattern size, more will be the nodes in network thus size of network will increase enabling it to store more data.\n"
      ],
      "metadata": {
        "id": "m78LHhsnsgUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3"
      ],
      "metadata": {
        "id": "SGgH-aCotJNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "function that converts MNIST digit data to the sort of patterns used in this simulation"
      ],
      "metadata": {
        "id": "Tcr6ESLCtPMZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5aiTefmvalq"
      },
      "outputs": [],
      "source": [
        "# Q3: Function to convert MNIST data to Hopfield-friendly patterns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from PIL import Image\n",
        "\n",
        "# Loading the MNIST dataset using TensorFlow/Keras\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Visualizing an image from the training set\n",
        "Image.fromarray(training_images[2]).resize((100, 100)).show()\n",
        "\n",
        "def perform_thresholding(images, threshold=127, pattern_size=28):\n",
        "    thresholded_images = np.zeros((len(images), pattern_size, pattern_size))\n",
        "    for i in range(len(images)):\n",
        "        img_boolean = (images[i] >= threshold)\n",
        "        img_int = img_boolean.astype(int)\n",
        "        img_int[img_int == 0] = -1\n",
        "        thresholded_images[i, :, :] = img_int\n",
        "    return thresholded_images\n",
        "\n",
        "# Preprocess MNIST dataset\n",
        "training_conv = perform_thresholding(training_images)\n",
        "test_conv = perform_thresholding(test_images)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3il356IRvanE"
      },
      "outputs": [],
      "source": [
        "print(\"Training Data Dimensions:\",training_images.shape)\n",
        "print(\"Test Data Dimensions:\",test_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that training set contains 60000 images and test set contains 10000 images. Images are of dimension 28*28.\n",
        "Also images are stored as pixel intensity ranging from 0 to 255.\n",
        "We need to convert this data to our desired Hopfield friendly pattern. For this we will have a threshold of 127.\n",
        "For pixel intensity less than 127, we will set it to -1 and pixel intensity greater than 127 will be set to 1.\n",
        "Doing this will make our image dataset correspond to the hopfield dataset"
      ],
      "metadata": {
        "id": "dzX2ryMyt5Tp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXd_JcJYvapZ"
      },
      "outputs": [],
      "source": [
        "def perform_thresholding(training_images, threshold=127, pattern_size = 28):\n",
        "    training_conv = np.zeros((len(training_images),pattern_size,pattern_size))\n",
        "    for i in range(len(training_images)):\n",
        "        threshold = 127\n",
        "        img_boolean = (training_images[i]>=threshold) # This will return array of true and false\n",
        "\n",
        "        # converting boolean to int\n",
        "        img_int = img_boolean.astype(int) # https://stackoverflow.com/questions/17506163/how-to-convert-a-boolean-array-to-an-int-array\n",
        "        img_int[img_int == 0] = -1 # Setting 0's to -1\n",
        "\n",
        "        training_conv[i,:,:] = img_int\n",
        "\n",
        "    return training_conv\n",
        "\n",
        "# Converting both training set and test set to hopfield suitable patterns\n",
        "training_conv = perform_thresholding(training_images)\n",
        "test_conv = perform_thresholding(test_images)\n",
        "# weights = calculate_weights_vectorized(training_conv[:60000,:,:], 28)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the converted number by plotting the pattern"
      ],
      "metadata": {
        "id": "ziXleqQbuCOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVXG_1Jsvar-"
      },
      "outputs": [],
      "source": [
        "plot_tools.plot_pattern(training_conv[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus, MNIST dataset has been succesfully converted to the sort of patterns used in Hopfield network\n",
        "\n",
        "# Question 4\n",
        "Can you write an MNIST classifier using the Hopfield network?. Can you characterize its performance using F-score, and compare with classical and deep supervised learning methods? Remember that you can always use multiple samples of the same digit even for the Hopfield network classifier. Summarize your sense of the merits and demerits of using a Hopfield network as a classifier (40 points)\n",
        "\n",
        "\n",
        "We have already converted MNIST data to desired patterns. Now next step is to train the weights using the training data"
      ],
      "metadata": {
        "id": "ov5-14v8uG2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv4MamGQvaua"
      },
      "outputs": [],
      "source": [
        "weights = calculate_weights_vectorized(training_conv, 28)\n",
        "# Visualizing weights\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyBTco_-vaw-"
      },
      "outputs": [],
      "source": [
        "# Weight shape\n",
        "weights.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M6Pct54va0J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# For calculating the overlap, we will not do it with every training example.\n",
        "# Instead, we will have one representative per image class.\n",
        "\n",
        "# Get the index of the first occurrence of each unique label\n",
        "idx = np.unique(training_labels, return_index=True)[1]\n",
        "\n",
        "# Select the images and labels corresponding to these unique indices\n",
        "state_comparison_list = training_images[idx]\n",
        "state_comparison_label = training_labels[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have our training data, and weights trained, also we have a comparison list over which we will calculate overlap.\n",
        "Now we perform network evolution on test set images."
      ],
      "metadata": {
        "id": "Aqo4BS-duUGD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5xmtVFNva2l"
      },
      "outputs": [],
      "source": [
        "# Q4: Using Hopfield network to classify MNIST digits\n",
        "def MNIST_network_evolution(state_comparison_list, state_comparison_label, test_conv, weights, number_of_evolutions=1, plot_final_state=False):\n",
        "    output = []\n",
        "    for test_image in test_conv:\n",
        "        S = test_image\n",
        "        state_list = [test_image]\n",
        "        for _ in range(number_of_evolutions):\n",
        "            state_list.append(network_update_optimized(S, weights))\n",
        "            S = state_list[-1]\n",
        "        op = pattern_tools.compute_overlap_list(state_list[-1], state_comparison_list)\n",
        "        output.append(state_comparison_label[op.argmax()])\n",
        "        if plot_final_state:\n",
        "            plot_tools.plot_pattern(state_list[-1])\n",
        "    return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_95zKFAva5B"
      },
      "outputs": [],
      "source": [
        "output = MNIST_network_evolution(state_comparison_list, state_comparison_label, test_conv[:200,:,:], weights, 1, False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding out the accuracy score and F1 Score for this model."
      ],
      "metadata": {
        "id": "wrN1L_hxuabQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_1idqoHva7a"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy and F1 score\n",
        "print(\"Accuracy is \", accuracy_score(output, test_labels[0:200]))\n",
        "print(\"F1 Score is \", f1_score(test_labels[0:200], output, average=\"weighted\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our model is behaving poorly. Now we will analyse what is going wrong.\n",
        "\n",
        "Lets visualize how our trained weights and images look like"
      ],
      "metadata": {
        "id": "I_T0FBNbudy1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-E8haNyva9t"
      },
      "outputs": [],
      "source": [
        "dummy_image = training_conv[2]\n",
        "print(\"Total pixels in image = \", len(dummy_image.flatten()))\n",
        "print(\"Total Positive Pixels = \", np.sum(dummy_image > 0))\n",
        "print(\"Total Negative Pixels = \", np.sum(dummy_image < 0))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7OtRBrSvbAY"
      },
      "outputs": [],
      "source": [
        "weights_unique, weight_counts = np.unique(weights, return_counts=True)\n",
        "print(\"Total neurons in weights = \", np.sum(weight_counts))\n",
        "print(\"Total number of Positive weights = \", np.sum(weight_counts[weights_unique<0]))\n",
        "print(\"Total number of Negative weights = \", np.sum(weight_counts[weights_unique>0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus we can see that majority of the pixels in the images are negative, this is because of weight formula assigns most of the weights to be positive(-1*-1 = 1) and summation causes it to become big positive numbers.\n",
        "\n",
        "And once the weights are positive, and most of the test input pixels will be -1, so (1 * -1 = -1) thus most pixels in the state evolution ends up being -1 and only where more of (+1) pixels are concentrated over large training example, we get +1.\n",
        "\n",
        "This is causing a effect that weights are getting trained in such a way that no matter what input is given, after few stages of network evolution, any test example is getting converged at same state values. We will visualize this below"
      ],
      "metadata": {
        "id": "2behkBuSumns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItUOkf8_vbDq"
      },
      "outputs": [],
      "source": [
        "# Passing 4 different test image inputs and visualizing state output\n",
        "output = MNIST_network_evolution(state_comparison_list, state_comparison_label, test_conv[0:4], weights, 3, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that, we used 4 different test set inputs, and passed it through network evolution.\n",
        "After evolution every different test is becoming to same state.\n",
        "This can be because images are highly correleated. REF\n",
        "I will be using techniques used in above research paper to improve upon the existing model's working\n",
        "\n",
        "Above research paper discusses that images are highly correleated, so they performed Deskewing and cropping operation as part of preprocessing. It also updated weight matrix by using Storkley method(wont be implementing this)."
      ],
      "metadata": {
        "id": "foabLA6WuwhN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOiVeGBtvbF9"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import interpolation\n",
        "\n",
        "def moments(image):\n",
        "    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
        "    totalImage = np.sum(image) #sum of pixels\n",
        "    m0 = np.sum(c0*image)/totalImage #mu_x\n",
        "    m1 = np.sum(c1*image)/totalImage #mu_y\n",
        "    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n",
        "    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n",
        "    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n",
        "    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n",
        "    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n",
        "    return mu_vector, covariance_matrix\n",
        "\n",
        "def deskew(image):\n",
        "    c,v = moments(image)\n",
        "    alpha = v[0,1]/v[0,0]\n",
        "    affine = np.array([[1,0],[alpha,1]])\n",
        "    ocenter = np.array(image.shape)/2.0\n",
        "    offset = c-np.dot(affine,ocenter)\n",
        "    return interpolation.affine_transform(image,affine,offset=offset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will now update the preprocessing function to deskew and crop images.\n",
        "Images are being cropped to be 14x14 pixels because it gives good results and eliminates redundant data(Optimal value discussed in research paper referenced below). Other values like thresholding for training set and test set used below are also the ones explored in research paper."
      ],
      "metadata": {
        "id": "oIju7Thfu1Et"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMdei--ivbIh"
      },
      "outputs": [],
      "source": [
        "def preprocessing_image_deskew_crop(training_images, threshold=127, pattern_size = 28):\n",
        "\n",
        "    training_conv = np.zeros((len(training_images),14,14))\n",
        "    for i in range(len(training_images)):\n",
        "\n",
        "        temp_img = deskew(training_images[i])\n",
        "\n",
        "        temp_img=temp_img[7:21,7:21]\n",
        "\n",
        "        img_boolean = (temp_img>=threshold) # This will return array of true and false\n",
        "\n",
        "        # converting boolean to int\n",
        "        img_int = img_boolean.astype(int) # https://stackoverflow.com/questions/17506163/how-to-convert-a-boolean-array-to-an-int-array\n",
        "        img_int[img_int == 0] = -1 # Setting 0's to -1\n",
        "\n",
        "        training_conv[i,:,:] = img_int\n",
        "\n",
        "    return training_conv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "deskew function typically corrects the skew in an image by calculating the moments of the image and applying an affine transformation to align it."
      ],
      "metadata": {
        "id": "5tslLPDy9yzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def deskew(image):\n",
        "    # Calculate image moments\n",
        "    m = cv2.moments(image)\n",
        "    if abs(m['mu02']) < 1e-2:\n",
        "        return image\n",
        "    skew = m['mu11'] / m['mu02']\n",
        "    M = np.float32([[1, skew, -0.5 * image.shape[0] * skew], [0, 1, 0]])\n",
        "    deskewed_img = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]), flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
        "    return deskewed_img\n"
      ],
      "metadata": {
        "id": "NaG02G0Z9xtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPERuX_JvbLE"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocessing_image_deskew_crop(training_images, threshold=127, pattern_size=28):\n",
        "    processed_images = []\n",
        "    for i in range(len(training_images)):\n",
        "        temp_img = deskew(training_images[i])\n",
        "\n",
        "        # Crop the image to focus on the center\n",
        "        temp_img = temp_img[7:21, 7:21]  # Example crop, adjust as needed\n",
        "\n",
        "        # Resize to the original pattern size\n",
        "        temp_img = cv2.resize(temp_img, (pattern_size, pattern_size))\n",
        "\n",
        "        # Apply thresholding\n",
        "        _, temp_img = cv2.threshold(temp_img, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Convert to binary (-1 and 1) as required for Hopfield networks\n",
        "        temp_img = (temp_img / 255).astype(int)\n",
        "        temp_img[temp_img == 0] = -1\n",
        "\n",
        "        processed_images.append(temp_img)\n",
        "\n",
        "    return np.array(processed_images)\n",
        "\n",
        "# Now you can use the function in your pipeline\n",
        "small_training_conv = preprocessing_image_deskew_crop(small_training_images, threshold=86)\n",
        "test_conv = preprocessing_image_deskew_crop(test_images, threshold=38)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = calculate_weights_vectorized(small_training_conv, 14)\n",
        "output = MNIST_network_evolution(small_training_conv, small_training_labels, test_conv, weights, 1,False)"
      ],
      "metadata": {
        "id": "zvwKaqIQ-P4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking out the accuracy and F1 score"
      ],
      "metadata": {
        "id": "iDkzEH3Iu_sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "print(\"Accuracy is \", accuracy_score(test_labels, output))\n",
        "print(\"F1 Score is \", f1_score(test_labels, output, average=\"weighted\"))\n"
      ],
      "metadata": {
        "id": "wES9FDzE8kMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison: We can see that normally without cropping and deskewing process, our model was only outputing 1 label in output.\n",
        "But after the deskewing and cropping, and using less training images, I was able to get better accuracy.\n",
        "It took lots of hits and trials and parameter tuning and taking help of research paper to get good parameters to get a accuracy of around 50-60% and F1 score of 0.56.\n",
        "Comparing to classical algorithm, this is very poor, since this required lots of preprocessing and lots of praying that certain parameters give good outcome, whereas classical algorithms are very efficient, classical algo. Here classical algorithms like random forest and SVM are getting 90% + accuracy.\n",
        "Deep learning algorithms on other hand are getting accuracy of 99% +.\n",
        "\n",
        "Merits:\n",
        "\n",
        "Hopfield network is a very simple unsupervised learning algorithm, and was performing well in the patterns example when informativeness of cue wasnt bad and pattern size was high\n",
        "Hopfield is easy to implement and can behave as a few shot learning algorithm given that data is suitable.\n",
        "Vectorized implementation of Hopfield is very fast.\n",
        "Demerits:\n",
        "\n",
        "Hopfield network has pretty limited capacity and cant be used to train lots of patterns.\n",
        "Hopfield network is a very basic model and would work better with advancements and improvements as we saw that it performed poorly on MNIST dataset.\n",
        "Hopfield network can get to local minima state instead of global minima REF\n",
        "If patterns are somewhat similar, model will behave poorly\n",
        "Weights are symmetric making weights store only half the information at the space it uses.\n",
        "Weights being symmetrical is not biologically plausible"
      ],
      "metadata": {
        "id": "1Xsd3sLIvHOA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMUd24MUvbQG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bnd6U5xvbSz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiE7JIzcvbVQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae8uDhafvbYB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubnfvLKAvba3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1zR_8usvbde"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FJBmXIEvbgC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bclodDyvbjN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUoBCkvMvbl5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZRABZyzvboo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLjdNBFbvbqg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3ogjdihvbtW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bwfHGXlvbwJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpEjPIbovbyx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G73hmKwvb1E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mm5Ty5Yvb32"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMPc8eMWvb6Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5J67xOUjvb9M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc1tcfUpvb_4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXSPeG36vcDp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvePCqOCvcFv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRDqmAhavcIn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sy9VVyrvcLD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTlO5Hj4vcOE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufowVpZQvcPy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQULHVxavcSd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZ72MRD6vcVf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXAcW091vcYD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIsPz7-Gvca2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f35qi_A3vcdm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMeVOQvpvcho"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4bZNFgpvckY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVmLCK-Kvcm3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm0X4kOzvcp7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvbJgJIdvcsf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4yKBwU0vcu-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOkFKGpGvczU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzeXLjJQJtFi4yYVQcCsW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}